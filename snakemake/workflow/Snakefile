"""
######################################################
###      _                _                  _      ##
###     | |              | |                | |     ##
###   __| | ___  ___ __ _| |_ ___  _ __ ___ | |__   ##
###  / _` |/ _ \/ __/ _` | __/ _ \| '_ ` _ \| '_ \  ##
### | (_| |  __/ (_| (_| | || (_) | | | | | | |_) | ##
###  \__,_|\___|\___\__,_|\__\___/|_| |_| |_|_.__/  ##
###                                                 ##                                   
######################################################             

The snakefile that runs decatomb. decatomb is a 'fast' version of hecatomb (https://github.com/shandley/hecatomb). decatomb foregoes all of the computationally expensive analysis of individual reads and focuses effort on the analysis of contigs.

Written by: Scott Handley (handley.scott@gmail.com), March 2021

Example launch script: snakemake --configfile ../config/sample_config.yaml --cores 32 -s Snakefile --resources mem_mb=32000

You can do a 'dry run' with the addition on the -n flag.

"""

# Python imports
import os
import sys

"""
Summary:
    # Step 0: Preprocessing (Rule: 00_preprocessing.smk)
    # Step 1: Assembly (Rule: 01_assembly.smk)
    # Step 2: Annotation (Rule: 02_annotate.smk)
"""

if not config:
    sys.stderr.write("FATAL: Please define a config file using the --configfile command line option.\n")
    sys.stderr.write("examples are provided in the Git repo\n")
    sys.exit()

# Set base database directories
DBDIR = config['Paths']['Databases']

# Paths for our data. This is where we will read and put things
READDIR = config['Paths']['Reads']

# Results directory
# Should not be a subdirectory to READDIR. Put it somewhere else!
RESULTS = config['Paths']['Results']

# Base RESULTS directories
ASSEMBLY = os.path.join(RESULTS, "ASSEMBLY")
QC = os.path.join(RESULTS, "QC")
LOGS = os.path.join(RESULTS, "LOGS")
STATS = os.path.join(RESULTS, "STATS")
RESULTS = os.path.join(RESULTS, "RESULTS")
BENCH = os.path.join(RESULTS, "BENCHMARKS")
TMPDIR = config['Paths']['Temp']
#if not os.path.exists(TMPDIR):
#    os.makedirs(TMPDIR, exist_ok=True)
    
# Database sub-directories
CONPATH = os.path.join(DBDIR, "contaminants")
HOST = config['Paths']['Host']
HOSTPATH = os.path.join(DBDIR, "host", HOST, "masked_ref.fa.gz")
TAX = os.path.join(DBDIR, "tax", "taxonomy")
TABLES = os.path.join(DBDIR, "tables")

fatal_errors = False
fatal_messages = []

###################################################################
#                                                                 #
# Read the sequence files and parse the file names.               #
#                                                                 #
###################################################################

SAMPLES,EXTENSIONS = glob_wildcards(os.path.join(READDIR, '{sample}_R1{extensions}'))

if not EXTENSIONS:
    sys.stderr.write("""
        FATAL: We could not parse the sequence file names.
        We are expecting {sample}_R1{extension}, and so your files
        should contain the characters '_R1' in the fwd reads
        and '_R2' in the rev reads
        """)
    sys.exit()
# we just get the generic extension. This is changed in Step 1/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-02/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-0218-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile18-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile

file_extension = EXTENSIONS[0]
# a convenience so we don't need to use '{sample}_R1' all the time
PATTERN = '{sample}'
PATTERN_R1 = '{sample}_R1'
PATTERN_R2 = '{sample}_R2'

if len(SAMPLES) == 0:
    sys.stderr.write("FATAL: We could not detect any samples at all.\n")
    sys.stderr.write("You should complain to Rob\n")
    sys.exit()

include: "rules/00_preprocessing.smk",
include: "rules/01_assembly.smk"
#include: "rules/02_annotate.smk"

rule all:
    input:
        #### Output files from 00_preprocessing.smk
        expand(os.path.join(QC, "CLUSTERED", PATTERN_R1 + ".deduped.out.fastq"), sample=SAMPLES),
        #### Output files from 01_assembly.smk
        expand(os.path.join(ASSEMBLY, PATTERN_R1 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN_R2 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN, PATTERN + ".contigs.fa"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs_size_selected.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.stats"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "assembly.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary.stats"),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".aln.sam.gz"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".unmapped.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".cov_stats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".rpkm"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".statsfile"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".scafstats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_contig_counts.tsv"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING",  "contig_count_table.tsv"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary_properties.gc"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary_properties.tetramer"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary_properties.tsv")
        #### Output files from 02_annotate.smk
        
        
        


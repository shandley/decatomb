"""
The snakefile that runs hecatomb.

This snakefile automatically calls the snakefiles in [rules](rules) to figure out the path.

Rob Edwards, October 2020

# Example launch script:  snakemake --configfile ../config/test_config.yaml --cores 64 -s Snakefile --resources mem_mb=100000

"""


import os
import sys


"""
Summary:
    # Step 0: Preprocessing (Rule: 00_preprocessing.smk)
    # Step 1: Taxonomic Assignment (Rule: 01_taxonomic_assignment.smk)
    # Step 2: Compile Results (Rule: 02_compile_results.smk)
"""

if not config:
    sys.stderr.write("FATAL: Please define a config file using the --configfile command line option.\n")
    sys.stderr.write("examples are provided in the Git repo\n")
    sys.exit()

# Set base database directories
DBDIR = config['Paths']['Databases']

# Paths for our data. This is where we will read and put things
READDIR = config['Paths']['Reads']

# Results directory
# Should not be a subdirectory to READDIR. Put it somewhere else!
RESULTS = config['Paths']['Results']

# Base RESULTS directories
ASSEMBLY = os.path.join(RESULTS, "ASSEMBLY")
QC = os.path.join(RESULTS, "QC")
LOGS = os.path.join(RESULTS, "LOGS")
STATS = os.path.join(RESULTS, "STATS")
RESULTS = os.path.join(RESULTS, "RESULTS")
BENCH = os.path.join(RESULTS, "BENCHMARKS")
TMPDIR = config['Paths']['Temp']
#if not os.path.exists(TMPDIR):
#    os.makedirs(TMPDIR, exist_ok=True)
    
# Database sub-directories
CONPATH = os.path.join(DBDIR, "contaminants")
HOST = config['Paths']['Host']
HOSTPATH = os.path.join(DBDIR, "host", HOST, "masked_ref.fa.gz")
TAX = os.path.join(DBDIR, "tax", "taxonomy")
TABLES = os.path.join(DBDIR, "tables")

fatal_errors = False
fatal_messages = []

###################################################################
#                                                                 #
# REFERENCE DATABASES                                             #
#                                                                 #
###################################################################

# Base path for protein sequence reference databases
PROTPATH = os.path.join(DBDIR, "proteins")
if not os.path.exists(PROTPATH):
    fatal_messages.append("protein databases")
    fatal_errors = True

# Primary aa search database:
# The virus protein database, clustered at 99% with cd-hit    
UNIVIRDB = os.path.join(PROTPATH, "virus_primary_aa")
if not os.path.exists(UNIVIRDB):
    fatal_messages.append(UNIVIRDB)
    fatal_errors = True

# Secondary aa search database
# UniRef50 + primary aa search database
UNIREF50VIR = os.path.join(PROTPATH, "virus_secondary_aa")
if not os.path.exists(UNIREF50VIR):
 fatal_messages.append(UNIREF50VIR)
 fatal_errors = True

# output directories for our translated (nt-to-aa) searches
PRIMARY_AA_OUT = os.path.join(RESULTS, "MMSEQS_AA_PRIMARY")
SECONDARY_AA_OUT = os.path.join(RESULTS, "MMSEQS_AA_SECONDARY")
PRIMARY_NT_OUT = os.path.join(RESULTS, "MMSEQS_NT_PRIMARY")
SECONDARY_NT_OUT = os.path.join(RESULTS, "MMSEQS_NT_SECONDARY")

# Base path for nucleotide sequence reference databases
NUCLPATH = os.path.join(DBDIR, "nt")

# The virus nucleotide database, clustered at 100% with linclust
NCBIVIRDB = os.path.join(NUCLPATH, "nt", "virus_primary_nt")
if not os.path.exists(NCBIVIRDB):
 fatal_messages.append(NCBIVIRDB)
 fatal_errors = True
 
# Polymicrobial + plant + virus database
POLYMICRODB = os.path.join(NUCLPATH, "nt", "virus_secondary_nt")
if not os.path.exists(POLYMICRODB):
   fatal_messages.append("nucleotide database {POLYMICRODB}")
   fatal_errors = True

# output directories for our untranslated (nt-to-nt) searches
PRIMARY_NT_OUT = os.path.join(RESULTS, "MMSEQS_NT_PRIMARY")
SECONDARY_NT_OUT = os.path.join(RESULTS, "MMSEQS_NT_SECONDARY")

###################################################################
#                                                                 #
# Taxonomy databases and related information                      #
#                                                                 #
###################################################################

#PHAGE_LINEAGES = os.path.join(DBDIR, "phages", "phage_taxonomic_lineages.txt")
#if not os.path.exists(PHAGE_LINEAGES):
#    fatal_messages.append("phages/phage_taxonomic_lineages.txt")
#    fatal_errors = True

#TAXPATH  = os.path.join(DBDIR, "taxonomy")
#TAXTAX = os.path.join(TAXPATH, "taxonomizr_accessionTaxa.sql")
#if not os.path.exists(TAXTAX):
#    fatal_messages.append(f"taxonomizr database {TAXTAX}")
#    fatal_errors = True

# Bacterial virus masked database for section 07 mmseqs pviral check

#BVMDB = os.path.join(NUCLPATH, "bac_virus_masked", "nt.fnaDB")
#if not os.path.exists(BVMDB):
#    fatal_messages.append(BVMDB)
#    fatal_errors = True


###################################################################
#                                                                 #
# Fatal errors should all be resolved by the download databsaes   #
#                                                                 #
###################################################################

#if fatal_errors:
#    sys.stderr.write("""
#**** FATAL ERRORS ****

#We can't proceed because we can't find one or more of the databases.
#You probably need to download the databases before you can continue.

#Please use the snakefile: 
#   download_databases.smk

#To download and install all the databases.

#Here are a list of the databases that are currently missing:
#""")
#    sys.stderr.write("\n".join(fatal_messages))
#    sys.stderr.write("\n\n")
#    sys.exit(5)

###################################################################
#                                                                 #
# Read the sequence files and parse the file names.               #
#                                                                 #
###################################################################

SAMPLES,EXTENSIONS = glob_wildcards(os.path.join(READDIR, '{sample}_R1{extensions}'))

if not EXTENSIONS:
    sys.stderr.write("""
        FATAL: We could not parse the sequence file names.
        We are expecting {sample}_R1{extension}, and so your files
        should contain the characters '_R1' in the fwd reads
        and '_R2' in the rev reads
        """)
    sys.exit()
# we just get the generic extension. This is changed in Step 1/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-02/Volumes/Macintosh HD/Users/shandley/Library/Caches/Nova/42111DAF-0218-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile18-485F-908B-6E1034888DEE/10.39.174.207/mnt/data3/shandley/dev/hecatomb_v_2/hecatomb/snakemake/workflow/Snakefile

file_extension = EXTENSIONS[0]
# a convenience so we don't need to use '{sample}_R1' all the time
PATTERN = '{sample}'
PATTERN_R1 = '{sample}_R1'
PATTERN_R2 = '{sample}_R2'

if len(SAMPLES) == 0:
    sys.stderr.write("FATAL: We could not detect any samples at all.\n")
    sys.stderr.write("You should complain to Rob\n")
    sys.exit()

include: "rules/00_preprocessing.smk"
#include: "rules/01_taxonomic_assignment.smk",
#include: "rules/02_compile_results.smk"

rule all:
    input:
        #### Output files from 00_preprocessing.smk
        os.path.join(RESULTS, "seqtable_all.tsv"),
        os.path.join(RESULTS, "seqtable.fasta"),
        os.path.join(RESULTS, "seqtable.stats"),
        os.path.join(RESULTS, "seqtable.fasta.fai"),
        os.path.join(RESULTS, "seqtable_properties.gc"),
        os.path.join(RESULTS, "seqtable_properties.tetramer"),
        os.path.join(RESULTS, "seqtable_properties.tsv"),
        ## Assembly out from 00_preprocessing.smk
        expand(os.path.join(ASSEMBLY, PATTERN_R1 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN_R2 + ".norm.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, PATTERN, PATTERN + ".contigs.fa"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs_size_selected.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "all_megahit_contigs.stats"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "assembly.fasta"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary.stats"),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".aln.sam.gz"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".unmapped.fastq"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".cov_stats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".rpkm"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".statsfile"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + ".scafstats"), sample=SAMPLES),
        expand(os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING", PATTERN + "_contig_counts.tsv"), sample=SAMPLES),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "MAPPING",  "contig_count_table.tsv"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary_properties.gc"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary_properties.tetramer"),
        os.path.join(ASSEMBLY, "CONTIG_DICTIONARY", "FLYE", "contig_dictionary_properties.tsv")
        #### Output file from 01_taxonomic_assignment.smk
        ## Primary (virus protein database) translated (nt-to-aa) search
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_lca.tsv"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_report"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_report"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_aln"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_aln_sorted"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_classified.fasta"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_unclassified.fasta"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_virus_order_summary.tsv"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_virus_family_summary.tsv"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_virus_genus_summary.tsv"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_virus_species_summary.tsv"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_only.tsv"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_tophit_broken_taxID.tsv"),
        #os.path.join(PRIMARY_AA_OUT, "MMSEQS_AA_PRIMARY_summary.tsv"),
        ## Secondary (likely viral to transkingdom database) translated (nt-to-aa) search
        #os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_lca.tsv"),
        #os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_report"),
        #os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_tophit_report"),
        #os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_tophit_aln"),
        #os.path.join(SECONDARY_AA_OUT, "MMSEQS_AA_SECONDARY_tophit_aln_sorted"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.tax_tmp_updated.tsv"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.kingdom.freq"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.unclass_superkingdom.freq"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.keyword_nonviral.freq"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.keyword_nonviral.list"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.keyword_bac.freq"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.keyword_vir.freq"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.keyword_vir.list"),
        #os.path.join(SECONDARY_AA_OUT, "tophit.keyword_all.list"),
        #os.path.join(SECONDARY_AA_OUT, "lca_virus_root.vir.tsv"),
        #os.path.join(SECONDARY_AA_OUT, "lca_unclass.vir.tsv"),
        #os.path.join(SECONDARY_AA_OUT, "translated_final.tsv"),
        #os.path.join(SECONDARY_AA_OUT, "translated_unclassified.fasta"),
        ## Primary untranslated (nt-to-nt) search
        #os.path.join(PRIMARY_NT_OUT, "queryDB"),
        #os.path.join(PRIMARY_NT_OUT, "results", "result.index"),
        #os.path.join(PRIMARY_NT_OUT, "results", "firsthit.index"),
        #os.path.join(PRIMARY_NT_OUT, "results", "result.m8"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt_phylum_summary.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt_class_summary.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt_class_summary.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt_order_summary.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt_family_summary.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt_genus_summary.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "primary_nt_species_summary.tsv"),
        #os.path.join(PRIMARY_NT_OUT, "classified_seqs.fasta"),
        #os.path.join(PRIMARY_NT_OUT, "unclassified_seqs.fasta")
        ## Secondary untranslated (nt-to-nt) search
        #os.path.join(SECONDARY_NT_OUT, "queryDB"),
        #os.path.join(SECONDARY_NT_OUT, "results", "result.index"),
        #os.path.join(SECONDARY_NT_OUT, "results", "tophit.index"),
        #os.path.join(SECONDARY_NT_OUT, "results", "tophit.m8"),
        #os.path.join(SECONDARY_NT_OUT, "SECONDARY_nt.tsv"),
        #os.path.join(SECONDARY_NT_OUT, "SECONDARY_nt_phylum_summary.tsv"),
        #os.path.join(SECONDARY_NT_OUT, "SECONDARY_nt_class_summary.tsv"),
        #os.path.join(SECONDARY_NT_OUT, "SECONDARY_nt_order_summary.tsv"),
        #os.path.join(SECONDARY_NT_OUT, "SECONDARY_nt_family_summary.tsv"),
        #os.path.join(SECONDARY_NT_OUT, "SECONDARY_nt_genus_summary.tsv"),
        #os.path.join(SECONDARY_NT_OUT, "SECONDARY_nt_species_summary.tsv"),
        #os.path.join(SECONDARY_NT_OUT, "results", "all.m8"),
        #os.path.join(SECONDARY_NT_OUT, "results", "secondary_nt_lca.tsv")
        
        

